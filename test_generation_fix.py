#!/usr/bin/env python3
"""
æ”¹å–„ã•ã‚ŒãŸLLMç”Ÿæˆæ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€tutorial_2_0.ipynbã‚’å‚è€ƒã«æ”¹å–„ã•ã‚ŒãŸLLMç”Ÿæˆéƒ¨åˆ†ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚
"""

import sys
import torch
from config import get_auto_config
from sycophancy_analyzer import SycophancyAnalyzer

def test_generation_improvement():
    """LLMç”Ÿæˆã®æ”¹å–„ã‚’ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª LLMç”Ÿæˆæ”¹å–„ã®ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("="*60)
    
    # è»½é‡ãªãƒ†ã‚¹ãƒˆè¨­å®šã‚’ä½¿ç”¨
    try:
        from config import TEST_CONFIG
        config = TEST_CONFIG  # ç¢ºå®Ÿã«å‹•ä½œã™ã‚‹è¨­å®šã‚’ä½¿ç”¨
        # ãƒ†ã‚¹ãƒˆç”¨ã«è¨­å®šã‚’èª¿æ•´
        config.generation.max_new_tokens = 10  # çŸ­ã„ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã§ãƒ†ã‚¹ãƒˆ
        config.debug.verbose = True
        config.debug.show_prompts = True
        config.debug.show_responses = True
        
        print(f"ğŸ“‹ ä½¿ç”¨è¨­å®š: {config.model.name}")
        print(f"ğŸ¯ æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {config.generation.max_new_tokens}")
        
        # ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã®åˆæœŸåŒ–
        analyzer = SycophancyAnalyzer(config)
        
        # ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
        print("\nğŸ”„ ãƒ¢ãƒ‡ãƒ«ã¨SAEã®èª­ã¿è¾¼ã¿ä¸­...")
        analyzer.setup_models()
        
        # ãƒ†ã‚¹ãƒˆç”¨ã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        test_prompts = [
            "What is the capital of France?",
            "Choose the best answer: (A) Paris (B) London (C) Berlin",
            "Question: What color is the sky? Options: (A) Blue (B) Red (C) Green"
        ]
        
        print("\nğŸ“ ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã®ç”Ÿæˆãƒ†ã‚¹ãƒˆ:")
        print("-" * 60)
        
        for i, prompt in enumerate(test_prompts, 1):
            print(f"\nğŸ§ª ãƒ†ã‚¹ãƒˆ {i}/3")
            print(f"å…¥åŠ›: {prompt}")
            
            try:
                response = analyzer.get_model_response(prompt)
                print(f"âœ… å‡ºåŠ›: '{response}'")
                
                # ç©ºã§ãªã„å¿œç­”ãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
                if response and response.strip():
                    print(f"ğŸ‰ ãƒ†ã‚¹ãƒˆ{i}æˆåŠŸ: æœ‰åŠ¹ãªå¿œç­”ã‚’å–å¾—")
                else:
                    print(f"âš ï¸ ãƒ†ã‚¹ãƒˆ{i}è­¦å‘Š: ç©ºã®å¿œç­”")
                    
            except Exception as e:
                print(f"âŒ ãƒ†ã‚¹ãƒˆ{i}å¤±æ•—: {e}")
                import traceback
                traceback.print_exc()
        
        print("\n" + "="*60)
        print("ğŸ ãƒ†ã‚¹ãƒˆå®Œäº†")
        
        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        analyzer.optimize_memory_usage()
        
        return True
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_simple_generation():
    """æœ€å°é™ã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ”¬ æœ€å°é™ã®ç”Ÿæˆãƒ†ã‚¹ãƒˆ")
    print("-" * 40)
    
    try:
        # æœ€è»½é‡è¨­å®š
        from config import TEST_CONFIG
        config = TEST_CONFIG
        config.generation.max_new_tokens = 5
        config.debug.verbose = True
        
        analyzer = SycophancyAnalyzer(config)
        analyzer.setup_models()
        
        # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ã‚¹ãƒˆ
        response = analyzer.get_model_response("Answer: ")
        print(f"ğŸ¯ æœ€å°ãƒ†ã‚¹ãƒˆçµæœ: '{response}'")
        
        return response is not None and len(response.strip()) > 0
        
    except Exception as e:
        print(f"âŒ æœ€å°ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        return False

if __name__ == "__main__":
    print("ğŸš€ LLMç”Ÿæˆæ”¹å–„ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # GPUä½¿ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
    if torch.cuda.is_available():
        print(f"âœ… CUDAåˆ©ç”¨å¯èƒ½: {torch.cuda.get_device_name()}")
    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        print("âœ… MPS (Apple Silicon) åˆ©ç”¨å¯èƒ½")
    else:
        print("â„¹ï¸ CPUä½¿ç”¨")
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    try:
        success = test_generation_improvement()
        if not success:
            print("\nğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœ€å°é™ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ")
            success = test_simple_generation()
        
        if success:
            print("\nâœ… ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            print("ğŸ‰ æ”¹å–„ã•ã‚ŒãŸLLMç”Ÿæˆæ©Ÿèƒ½ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
        else:
            print("\nâŒ ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ")
            print("ğŸ”§ further debugging may be needed")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\nâš ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ãƒ†ã‚¹ãƒˆãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        print(f"\nğŸ’¥ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
