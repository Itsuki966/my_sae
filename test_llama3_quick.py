#!/usr/bin/env python3
"""
Llama3ã®å›ç­”ç”Ÿæˆä¿®æ­£ã‚’ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

def test_llama3_generation():
    """Llama3ã®å›ç­”ç”Ÿæˆãƒ†ã‚¹ãƒˆ"""
    print("ğŸ¦™ Llama3ä¿®æ­£ç‰ˆã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ")
    print("="*50)
    
    try:
        from sycophancy_analyzer import SycophancyAnalyzer
        from config import LLAMA3_TEST_CONFIG
        
        print("ğŸ”§ åˆ†æå™¨åˆæœŸåŒ–ä¸­...")
        analyzer = SycophancyAnalyzer(LLAMA3_TEST_CONFIG)
        
        print("ğŸ”„ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
        analyzer.setup_models()
        
        print("\nğŸ“ ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:")
        simple_prompt = "What is 2 + 2? Answer: A) 3, B) 4, C) 5. Just respond with the letter:"
        
        print(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {simple_prompt}")
        print("="*60)
        
        response = analyzer.get_model_response(simple_prompt)
        
        print("="*60)
        print(f"âœ… å¿œç­”: '{response}'")
        print(f"ğŸ“ å¿œç­”é•·: {len(response)}æ–‡å­—")
        
        if response and len(response.strip()) > 0:
            print("ğŸ‰ å›ç­”ç”ŸæˆæˆåŠŸ!")
            
            # å›ç­”æŠ½å‡ºãƒ†ã‚¹ãƒˆ
            extracted = analyzer.extract_answer_letter(response)
            if extracted:
                print(f"âœ… å›ç­”æŠ½å‡ºæˆåŠŸ: {extracted}")
                if extracted == 'B':
                    print("ğŸ¯ æ­£è§£! (2+2=4)")
                else:
                    print(f"âš ï¸ æœŸå¾…ã—ãŸå›ç­”ã¨ç•°ãªã‚Šã¾ã™ (æœŸå¾…: B, å®Ÿéš›: {extracted})")
            else:
                print("âš ï¸ å›ç­”æŠ½å‡ºå¤±æ•—")
            
            return True
        else:
            print("âŒ å¿œç­”ãŒç©ºã§ã™")
            return False
            
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    test_llama3_generation()
