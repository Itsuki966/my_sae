#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SAEш┐ОхРИцАзхИЖцЮР - хоЯщиУшинхоЪчобчРЖ
хоЯщиУуБлщЦвуВПуВЛуГЮуВ╕уГГуВпуГКуГ│уГРуГ╝уВТф╕АхЕГчобчРЖуБЧуАБшинхоЪхдЙцЫ┤уВТхо╣цШУуБлуБЩуВЛ
"""

import torch
from dataclasses import dataclass
from typing import Optional

@dataclass
class ExperimentConfig:
    """хоЯщиУшинхоЪуВТчобчРЖуБЩуВЛуГЗуГ╝уВ┐уВпуГйуВ╣"""
    
    # ===== ЁЯдЦ уГвуГЗуГлшинхоЪ =====
    model_name: str = "pythia-70m-deduped"
    sae_release: str = "pythia-70m-deduped-res-sm"
    sae_id: str = "blocks.5.hook_resid_post"
    
    # ===== ЁЯУК уГЗуГ╝уВ┐шинхоЪ =====
    dataset_path: str = "eval_dataset/are_you_sure.jsonl"
    sample_size: int = 50
    
    # ===== ЁЯОЫя╕П чФЯцИРшинхоЪ =====
    max_new_tokens: int = 8
    temperature: float = 0.1
    do_sample: bool = True
    repetition_penalty: float = 1.0
    top_p: float = 1.0
    top_k: int = 50
    
    # ===== ЁЯФН хИЖцЮРшинхоЪ =====
    top_k_features: int = 20
    activation_threshold: float = 0.1
    
    # ===== ЁЯУЭ шбичд║шинхоЪ =====
    show_details: bool = True
    detail_samples: int = 3
    max_examples_shown: int = 3
    
    # ===== ЁЯРЫ уГЗуГРуГГуВ░шинхоЪ =====
    debug_extraction: bool = False
    debug_activations: bool = False
    verbose_logging: bool = False
    
    # ===== ЁЯТ╗ уВ╖уВ╣уГЖуГашинхоЪ =====
    device: Optional[str] = None
    random_seed: int = 42
    
    def __post_init__(self):
        """хИЭцЬЯхМЦх╛МуБохЗжчРЖ"""
        if self.device is None:
            if torch.backends.mps.is_available():
                self.device = "mps"
            elif torch.cuda.is_available():
                self.device = "cuda"
            else:
                self.device = "cpu"

# ===== ЁЯУЛ уГЧуГкуВ╗уГГуГИшинхоЪ =====

def get_quick_test_config() -> ExperimentConfig:
    """уВпуВдуГГуВпуГЖуВ╣уГИчФиуБошинхоЪ"""
    return ExperimentConfig(
        sample_size=10,
        max_new_tokens=5,
        temperature=0.0,
        show_details=True,
        detail_samples=5
    )

def get_full_analysis_config() -> ExperimentConfig:
    """хоМхЕихИЖцЮРчФиуБошинхоЪ"""
    return ExperimentConfig(
        sample_size=100,
        max_new_tokens=8,
        temperature=0.1,
        show_details=False,
        detail_samples=0
    )

def get_debug_config() -> ExperimentConfig:
    """уГЗуГРуГГуВ░чФиуБошинхоЪ"""
    return ExperimentConfig(
        sample_size=5,
        max_new_tokens=10,
        temperature=0.0,
        show_details=True,
        detail_samples=5,
        debug_extraction=True,
        debug_activations=True,
        verbose_logging=True
    )

def get_larger_model_config() -> ExperimentConfig:
    """уВИуВКхдзуБНуБкуГвуГЗуГлчФиуБошинхоЪ"""
    return ExperimentConfig(
        model_name="pythia-160m-deduped",
        sae_release="pythia-160m-deduped-res-sm",
        sae_id="blocks.7.hook_resid_post",
        sample_size=50,
        max_new_tokens=8,
        temperature=0.1
    )

def get_deterministic_config() -> ExperimentConfig:
    """хоМхЕиц▒║хоЪчЪДуБкшинхоЪ"""
    return ExperimentConfig(
        sample_size=50,
        max_new_tokens=5,
        temperature=0.0,
        do_sample=False,
        top_p=1.0,
        top_k=1
    )

# ===== ЁЯОп шинхоЪцдЬши╝ =====

def validate_config(config: ExperimentConfig) -> bool:
    """шинхоЪуБохжех╜УцАзуВТцдЬши╝"""
    errors = []
    
    # хЯ║цЬмуГБуВзуГГуВп
    if config.sample_size <= 0:
        errors.append("sample_size уБпцнгуБоцХ┤цХ░уБзуБВуВЛх┐ЕшжБуБМуБВуВКуБ╛уБЩ")
    
    if config.max_new_tokens <= 0:
        errors.append("max_new_tokens уБпцнгуБоцХ┤цХ░уБзуБВуВЛх┐ЕшжБуБМуБВуВКуБ╛уБЩ")
    
    if not (0.0 <= config.temperature <= 2.0):
        errors.append("temperature уБп 0.0-2.0 уБочпДхЫ▓уБзуБВуВЛх┐ЕшжБуБМуБВуВКуБ╛уБЩ")
    
    if not (0.0 <= config.top_p <= 1.0):
        errors.append("top_p уБп 0.0-1.0 уБочпДхЫ▓уБзуБВуВЛх┐ЕшжБуБМуБВуВКуБ╛уБЩ")
    
    if config.top_k_features <= 0:
        errors.append("top_k_features уБпцнгуБоцХ┤цХ░уБзуБВуВЛх┐ЕшжБуБМуБВуВКуБ╛уБЩ")
    
    # уГХуВбуВдуГлхнШхЬиуГБуВзуГГуВп
    import os
    if not os.path.exists(config.dataset_path):
        errors.append(f"уГЗуГ╝уВ┐уВ╗уГГуГИуГХуВбуВдуГлуБМшжЛуБдуБЛуВКуБ╛уБЫуВУ: {config.dataset_path}")
    
    # уВиуГйуГ╝хЗ║хКЫ
    if errors:
        print("тЭМ шинхоЪуВиуГйуГ╝:")
        for error in errors:
            print(f"   - {error}")
        return False
    
    print("тЬЕ шинхоЪцдЬши╝хоМф║Ж")
    return True

def print_config_summary(config: ExperimentConfig):
    """шинхоЪхЖЕхо╣уБоуВ╡уГЮуГкуГ╝уВТшбичд║"""
    print("ЁЯУЛ хоЯщиУшинхоЪуВ╡уГЮуГкуГ╝")
    print("=" * 40)
    
    print(f"ЁЯдЦ уГвуГЗуГл: {config.model_name}")
    print(f"ЁЯУК уВ╡уГ│уГЧуГлцХ░: {config.sample_size}")
    print(f"ЁЯТ╗ уГЗуГРуВдуВ╣: {config.device}")
    print(f"ЁЯОЫя╕П цЬАхдзуГИуГ╝уВпуГ│: {config.max_new_tokens}")
    print(f"ЁЯМбя╕П ц╕йх║ж: {config.temperature}")
    print(f"ЁЯФН шй│ч┤░шбичд║: {config.show_details}")
    
    if config.debug_extraction or config.debug_activations:
        print(f"ЁЯРЫ уГЗуГРуГГуВ░уГвуГ╝уГЙ: ON")
    
    print("=" * 40)

# ===== ЁЯУЪ ф╜┐чФиф╛Л =====

if __name__ == "__main__":
    print("ЁЯОп SAEш┐ОхРИцАзхИЖцЮР - шинхоЪчобчРЖуГЗуГв")
    print()
    
    # уГЗуГХуВйуГлуГИшинхоЪ
    print("1. уГЗуГХуВйуГлуГИшинхоЪ:")
    default_config = ExperimentConfig()
    print_config_summary(default_config)
    print()
    
    # уВпуВдуГГуВпуГЖуВ╣уГИшинхоЪ
    print("2. уВпуВдуГГуВпуГЖуВ╣уГИшинхоЪ:")
    quick_config = get_quick_test_config()
    print_config_summary(quick_config)
    print()
    
    # шинхоЪцдЬши╝
    print("3. шинхоЪцдЬши╝:")
    validate_config(default_config)
    print()
    
    print("ЁЯЪА хИйчФицЦ╣ц│Х:")
    print("   from experiment_config import ExperimentConfig, get_quick_test_config")
    print("   config = get_quick_test_config()")
    print("   # уБ╛уБЯуБп")
    print("   config = ExperimentConfig(sample_size=100, temperature=0.0)")
